{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee1940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a9b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_parquet = pd.read_parquet('../data/raw/reunion_segments.parquet')\n",
    "df_parquet = pd.DataFrame(raw_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d196af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parquet['altitude_profile'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_segment(altitude_profile, distance_profile, \n",
    "                grade_threshold=2.5, min_section_length=200):\n",
    "    \"\"\"\n",
    "    Cut a segment into meaningful sections (climbs, descents, flats) based on grade changes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    altitude_profile : array-like\n",
    "        Altitude values along the segment (meters)\n",
    "    distance_profile : array-like\n",
    "        Cumulative distance values (meters)\n",
    "    grade_threshold : float\n",
    "        Percentage grade change to trigger a new section (default: 2.5%)\n",
    "    min_section_length : float\n",
    "        Minimum length for a section in meters (default: 200m)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of dict : List of sections with type, grade, distance, elevation change, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    alt_array = np.array(altitude_profile)\n",
    "    dist_array = np.array(distance_profile)\n",
    "    \n",
    "    if len(alt_array) < 2 or len(dist_array) < 2:\n",
    "        return []\n",
    "    \n",
    "    # Calculate grade at each point (%)\n",
    "    grades = []\n",
    "    for i in range(len(alt_array) - 1):\n",
    "        distance_diff = dist_array[i + 1] - dist_array[i]\n",
    "        if distance_diff > 0:\n",
    "            elevation_diff = alt_array[i + 1] - alt_array[i]\n",
    "            grade = (elevation_diff / distance_diff) * 100\n",
    "            grades.append(grade)\n",
    "        else:\n",
    "            grades.append(0)\n",
    "    \n",
    "    # Smooth grades to reduce noise (moving average)\n",
    "    window_size = min(5, len(grades))\n",
    "    grades_smooth = np.convolve(grades, np.ones(window_size)/window_size, mode='same')\n",
    "    \n",
    "    # Detect section boundaries\n",
    "    sections = []\n",
    "    section_start_idx = 0\n",
    "    current_grade = grades_smooth[0]\n",
    "    \n",
    "    for i in range(1, len(grades_smooth)):\n",
    "        grade_change = abs(grades_smooth[i] - current_grade)\n",
    "        distance_covered = dist_array[i] - dist_array[section_start_idx]\n",
    "        \n",
    "        # Start new section if grade changes significantly AND minimum distance reached\n",
    "        if grade_change > grade_threshold and distance_covered >= min_section_length:\n",
    "            # Save current section\n",
    "            section = _create_section(\n",
    "                alt_array, dist_array, grades_smooth,\n",
    "                section_start_idx, i\n",
    "            )\n",
    "            if section:\n",
    "                sections.append(section)\n",
    "            \n",
    "            # Start new section\n",
    "            section_start_idx = i\n",
    "            current_grade = grades_smooth[i]\n",
    "    \n",
    "    # Add final section\n",
    "    section = _create_section(\n",
    "        alt_array, dist_array, grades_smooth,\n",
    "        section_start_idx, len(dist_array) - 1\n",
    "    )\n",
    "    if section:\n",
    "        sections.append(section)\n",
    "    \n",
    "    # Merge short sections with neighbors\n",
    "    sections = _merge_short_sections(sections, min_section_length)\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185ca663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_distance': 0,\n",
       "  'end_distance': 100,\n",
       "  'elevation_gain': np.float64(-3.6000000000000014)},\n",
       " {'start_distance': 100,\n",
       "  'end_distance': 200,\n",
       "  'elevation_gain': np.float64(7.200000000000003)},\n",
       " {'start_distance': 200,\n",
       "  'end_distance': 300,\n",
       "  'elevation_gain': np.float64(3.6000000000000085)},\n",
       " {'start_distance': 300,\n",
       "  'end_distance': 400,\n",
       "  'elevation_gain': np.float64(5.400000000000006)},\n",
       " {'start_distance': 400,\n",
       "  'end_distance': 500,\n",
       "  'elevation_gain': np.float64(4.0)},\n",
       " {'start_distance': 500,\n",
       "  'end_distance': 600,\n",
       "  'elevation_gain': np.float64(4.599999999999994)},\n",
       " {'start_distance': 600,\n",
       "  'end_distance': 700,\n",
       "  'elevation_gain': np.float64(4.199999999999989)},\n",
       " {'start_distance': 700,\n",
       "  'end_distance': 800,\n",
       "  'elevation_gain': np.float64(5.0)},\n",
       " {'start_distance': 800,\n",
       "  'end_distance': 900,\n",
       "  'elevation_gain': np.float64(4.400000000000006)},\n",
       " {'start_distance': 900,\n",
       "  'end_distance': 1000,\n",
       "  'elevation_gain': np.float64(4.200000000000003)},\n",
       " {'start_distance': 1000,\n",
       "  'end_distance': 1100,\n",
       "  'elevation_gain': np.float64(5.200000000000003)},\n",
       " {'start_distance': 1100,\n",
       "  'end_distance': 1200,\n",
       "  'elevation_gain': np.float64(3.0)},\n",
       " {'start_distance': 1200,\n",
       "  'end_distance': 1300,\n",
       "  'elevation_gain': np.float64(3.0)},\n",
       " {'start_distance': 1300,\n",
       "  'end_distance': 1400,\n",
       "  'elevation_gain': np.float64(4.0)},\n",
       " {'start_distance': 1400,\n",
       "  'end_distance': 1500,\n",
       "  'elevation_gain': np.float64(4.599999999999994)},\n",
       " {'start_distance': 1500,\n",
       "  'end_distance': 1600,\n",
       "  'elevation_gain': np.float64(5.199999999999989)},\n",
       " {'start_distance': 1600,\n",
       "  'end_distance': 1700,\n",
       "  'elevation_gain': np.float64(4.400000000000006)},\n",
       " {'start_distance': 1700,\n",
       "  'end_distance': 1800,\n",
       "  'elevation_gain': np.float64(6.800000000000011)},\n",
       " {'start_distance': 1800,\n",
       "  'end_distance': 1900,\n",
       "  'elevation_gain': np.float64(5.0)},\n",
       " {'start_distance': 1900,\n",
       "  'end_distance': 2000,\n",
       "  'elevation_gain': np.float64(4.800000000000011)},\n",
       " {'start_distance': 2000,\n",
       "  'end_distance': np.float64(2088.5),\n",
       "  'elevation_gain': np.float64(3.5999999999999943)}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_segment(df_parquet['altitude_profile'].iloc[0], df_parquet['distance_profile'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2dda3",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee21d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Function to extract features from a profile\n",
    "def extract_features(profile):\n",
    "    \"\"\"Extract simple features from 100m elevation profile\"\"\"\n",
    "    gains = [chunk['elevation_gain'] for chunk in profile]\n",
    "    \n",
    "    return {\n",
    "        'total_distance': profile[-1]['end_distance'],\n",
    "        'total_elevation_gain': sum(g for g in gains if g > 0),\n",
    "        'total_elevation_loss': sum(abs(g) for g in gains if g < 0),\n",
    "        'avg_grade': np.mean(gains) / 100 * 100,  # % moyen\n",
    "        'max_gain': max(gains),\n",
    "        'max_loss': min(gains),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c184a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_segments_df(df_parquet):\n",
    "    \"\"\"Build segments_df with profile column from raw parquet data\"\"\"\n",
    "    profiles = []\n",
    "    \n",
    "    for altitude, distance in zip(df_parquet['altitude_profile'], df_parquet['distance_profile']):\n",
    "        profile = cut_segment(altitude, distance)\n",
    "        profiles.append(profile)\n",
    "    \n",
    "    segments_df = df_parquet.copy()\n",
    "    segments_df['profile'] = profiles\n",
    "    \n",
    "    return segments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03cb2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Prepare training data\n",
    "def prepare_data(segments_df):\n",
    "    \"\"\"Prepare X and y from segments dataframe\"\"\"\n",
    "    features_list = []\n",
    "    times = []\n",
    "    \n",
    "    for _, row in segments_df.iterrows():\n",
    "        profile = row['profile']\n",
    "        time = row['average_top_10_time']\n",
    "        \n",
    "        if profile and time and not np.isnan(time):\n",
    "            features = extract_features(profile)\n",
    "            features_list.append(features)\n",
    "            times.append(time)\n",
    "    \n",
    "    X = pd.DataFrame(features_list)\n",
    "    y = np.array(times)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f07f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Train model\n",
    "def train_model(X, y):\n",
    "    \"\"\"Train a simple gradient boosting model\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"MAE: {mae:.0f}s ({mae/60:.1f} min)\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14bf532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Predict time for new profile\n",
    "def predict_time(model, profile):\n",
    "    \"\"\"Predict time for a new profile\"\"\"\n",
    "    features = extract_features(profile)\n",
    "    X = pd.DataFrame([features])\n",
    "    return model.predict(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c821dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 151s (2.5 min)\n",
      "R²: 0.923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% ============ USAGE ============\n",
    "\n",
    "# 1. Load your data (adapt to your actual data structure)\n",
    "segments_df = build_segments_df(df_parquet)\n",
    "\n",
    "# 2. Prepare data\n",
    "X, y = prepare_data(segments_df)\n",
    "\n",
    "# 3. Train\n",
    "model = train_model(X, y)\n",
    "\n",
    "# 4. Save model\n",
    "joblib.dump(model, '../src/models/time_predictor.joblib')\n",
    "\n",
    "# 5. Predict on new profile\n",
    "mon_profil = [\n",
    "    {'start_distance': 0, 'end_distance': 100, 'elevation_gain': -3.6},\n",
    "    {'start_distance': 100, 'end_distance': 200, 'elevation_gain': 7.2},\n",
    "    {'start_distance': 200, 'end_distance': 300, 'elevation_gain': 3.6},\n",
    "    {'start_distance': 300, 'end_distance': 400, 'elevation_gain': 5.4},\n",
    "    {'start_distance': 400, 'end_distance': 500, 'elevation_gain': 4.0},\n",
    "    # ... add more chunks\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc2e1937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps estimé: 191s (3.2 min)\n"
     ]
    }
   ],
   "source": [
    "predicted_time = predict_time(model, mon_profil)\n",
    "print(f\"Temps estimé: {predicted_time:.0f}s ({predicted_time/60:.1f} min)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
